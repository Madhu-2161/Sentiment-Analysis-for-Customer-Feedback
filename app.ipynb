{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit transformers torch pyngrok pandas --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmL8knAMp6jJ",
        "outputId": "343cae4a-9f9d-4750-cd6a-5a6d90ceba2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load sentiment model\n",
        "sentiment_model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)\n",
        "sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name)\n",
        "sentiment_model.eval()\n",
        "\n",
        "sentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "\n",
        "# Department mapping\n",
        "department_keywords = {\n",
        "    \"loan process\": [\"loan\", \"home loan\", \"personal loan\", \"loan process\"],\n",
        "    \"branch experience\": [\"branch\", \"staff\", \"manager\", \"in person\"],\n",
        "    \"customer service\": [\"customer service\", \"support\", \"call\", \"response\"],\n",
        "    \"account opening\": [\"account opening\", \"new account\", \"open account\"],\n",
        "    \"mobile app\": [\"app\", \"application\", \"mobile\", \"online\"],\n",
        "    \"charges/fees\": [\"charges\", \"fees\", \"hidden charge\", \"deduction\"],\n",
        "    \"credit card\": [\"credit card\", \"card limit\", \"card issue\"]\n",
        "}\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    inputs = sentiment_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = sentiment_model(**inputs)\n",
        "    pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return sentiment_labels[pred]\n",
        "\n",
        "def predict_service(text):\n",
        "    text_lower = text.lower()\n",
        "    for dept, keywords in department_keywords.items():\n",
        "        for kw in keywords:\n",
        "            if kw in text_lower:\n",
        "                return dept\n",
        "    return \"other\"\n",
        "\n",
        "# --- Streamlit UI ---\n",
        "st.title(\"Sentiment Analysis App\")\n",
        "st.write(\"Upload a `.csv` file with **two columns: City, Feedback**\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload CSV\", type=[\"csv\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    if \"City\" not in df.columns or \"Feedback\" not in df.columns:\n",
        "        st.error(\"CSV must contain 'City' and 'Feedback' columns.\")\n",
        "        st.stop()\n",
        "\n",
        "    df = df.dropna(subset=[\"City\", \"Feedback\"])\n",
        "    df[\"Sentiment\"] = df[\"Feedback\"].apply(predict_sentiment)\n",
        "    df[\"Department\"] = df[\"Feedback\"].apply(predict_service)\n",
        "\n",
        "    st.write(\"### 🔍 Prediction Results\")\n",
        "    st.dataframe(df)\n",
        "\n",
        "    st.write(\"### 📊 Sentiment Summary by Department (All Cities)\")\n",
        "    dept_summary = pd.crosstab(df[\"Department\"], df[\"Sentiment\"])\n",
        "    st.dataframe(dept_summary)\n",
        "    st.bar_chart(dept_summary)\n",
        "\n",
        "    st.write(\"### 🏙️ City-wise Department Sentiment Breakdown\")\n",
        "    grouped = df.groupby([\"City\", \"Department\", \"Sentiment\"]).size().unstack(fill_value=0)\n",
        "    st.dataframe(grouped)\n",
        "\n",
        "    st.write(\"### 🌍 Summary: Sentiment Distribution by City\")\n",
        "    city_summary = pd.crosstab(df[\"City\"], df[\"Sentiment\"])\n",
        "    st.dataframe(city_summary)\n",
        "    st.bar_chart(city_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uvtX6zKStoV",
        "outputId": "a9350cda-eb86-4a4f-8fdc-bfeeb7304027"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill all active tunnels\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "Cb3wNXpBtKzE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# Set your authtoken\n",
        "ngrok.set_auth_token(\"2zdLIdrYO2ChVzZ2tpYojT5k57z_2NBZ7wkjNskTzDaHEhZLf\")\n",
        "\n",
        "# Restart the Streamlit app\n",
        "get_ipython().system_raw(\"streamlit run app.py &\")\n",
        "\n",
        "# Wait a moment to ensure it's started\n",
        "time.sleep(3)\n",
        "\n",
        "# Start a fresh tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"✅ Streamlit App is live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ukukTdetOxa",
        "outputId": "34e1259c-8236-4e24-97b4-75487c5af20c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Streamlit App is live at: NgrokTunnel: \"https://2a3591e1b6a4.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}